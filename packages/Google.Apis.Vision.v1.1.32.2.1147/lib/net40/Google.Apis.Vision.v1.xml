<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Google.Apis.Vision.v1</name>
    </assembly>
    <members>
        <member name="T:Google.Apis.Vision.v1.VisionService">
            <summary>The Vision Service.</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionService.Version">
            <summary>The API version.</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionService.DiscoveryVersionUsed">
            <summary>The discovery version used to generate this service.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.VisionService.#ctor">
            <summary>Constructs a new service.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.VisionService.#ctor(Google.Apis.Services.BaseClientService.Initializer)">
            <summary>Constructs a new service.</summary>
            <param name="initializer">The service initializer.</param>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionService.Features">
            <summary>Gets the service supported features.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionService.Name">
            <summary>Gets the service name.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionService.BaseUri">
            <summary>Gets the service base URI.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionService.BasePath">
            <summary>Gets the service base path.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.VisionService.Scope">
            <summary>Available OAuth 2.0 scopes for use with the Google Cloud Vision API.</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionService.Scope.CloudPlatform">
            <summary>View and manage your data across Google Cloud Platform services</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionService.Scope.CloudVision">
            <summary>Apply machine learning models to understand and label images</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionService.Images">
            <summary>Gets the Images resource.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionService.Operations">
            <summary>Gets the Operations resource.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.VisionBaseServiceRequest`1">
            <summary>A base abstract class for Vision requests.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.#ctor(Google.Apis.Services.IClientService)">
            <summary>Constructs a new VisionBaseServiceRequest instance.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.Xgafv">
            <summary>V1 error format.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.XgafvEnum">
            <summary>V1 error format.</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.XgafvEnum.Value1">
            <summary>v1 error format</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.XgafvEnum.Value2">
            <summary>v2 error format</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.AccessToken">
            <summary>OAuth access token.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.Alt">
            <summary>Data format for response.</summary>
            [default: json]
        </member>
        <member name="T:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.AltEnum">
            <summary>Data format for response.</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.AltEnum.Json">
            <summary>Responses with Content-Type of application/json</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.AltEnum.Media">
            <summary>Media download with context-dependent Content-Type</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.AltEnum.Proto">
            <summary>Responses with Content-Type of application/x-protobuf</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.BearerToken">
            <summary>OAuth bearer token.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.Callback">
            <summary>JSONP</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.Fields">
            <summary>Selector specifying which fields to include in a partial response.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.Key">
            <summary>API key. Your API key identifies your project and provides you with API access, quota, and reports.
            Required unless you provide an OAuth 2.0 token.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.OauthToken">
            <summary>OAuth 2.0 token for the current user.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.Pp">
            <summary>Pretty-print response.</summary>
            [default: true]
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.PrettyPrint">
            <summary>Returns response with indentations and line breaks.</summary>
            [default: true]
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.QuotaUser">
            <summary>Available to use for quota purposes for server-side applications. Can be any arbitrary string
            assigned to a user, but should not exceed 40 characters.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.UploadType">
            <summary>Legacy upload protocol for media (e.g. "media", "multipart").</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.UploadProtocol">
            <summary>Upload protocol for media (e.g. "raw", "multipart").</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.VisionBaseServiceRequest`1.InitParameters">
            <summary>Initializes Vision parameter list.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.ImagesResource">
            <summary>The "images" collection of methods.</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.ImagesResource.service">
            <summary>The service which this resource belongs to.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.ImagesResource.#ctor(Google.Apis.Services.IClientService)">
            <summary>Constructs a new resource.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.ImagesResource.Annotate(Google.Apis.Vision.v1.Data.BatchAnnotateImagesRequest)">
            <summary>Run image detection and annotation for a batch of images.</summary>
            <param name="body">The body of the request.</param>
        </member>
        <member name="T:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest">
            <summary>Run image detection and annotation for a batch of images.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest.#ctor(Google.Apis.Services.IClientService,Google.Apis.Vision.v1.Data.BatchAnnotateImagesRequest)">
            <summary>Constructs a new Annotate request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest.Body">
            <summary>Gets or sets the body of this request.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest.GetBody">
            <summary>Returns the body of the request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.ImagesResource.AnnotateRequest.InitParameters">
            <summary>Initializes Annotate parameter list.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.OperationsResource">
            <summary>The "operations" collection of methods.</summary>
        </member>
        <member name="F:Google.Apis.Vision.v1.OperationsResource.service">
            <summary>The service which this resource belongs to.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.#ctor(Google.Apis.Services.IClientService)">
            <summary>Constructs a new resource.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.Cancel(Google.Apis.Vision.v1.Data.CancelOperationRequest,System.String)">
            <summary>Starts asynchronous cancellation on a long-running operation.  The server makes a best effort to
            cancel the operation, but success is not guaranteed.  If the server doesn't support this method, it returns
            `google.rpc.Code.UNIMPLEMENTED`.  Clients can use Operations.GetOperation or other methods to check whether
            the cancellation succeeded or whether the operation completed despite cancellation. On successful
            cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value
            with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.</summary>
            <param name="body">The body of the request.</param>
            <param name="name">The name of the operation resource to be cancelled.</param>
        </member>
        <member name="T:Google.Apis.Vision.v1.OperationsResource.CancelRequest">
            <summary>Starts asynchronous cancellation on a long-running operation.  The server makes a best effort to
            cancel the operation, but success is not guaranteed.  If the server doesn't support this method, it returns
            `google.rpc.Code.UNIMPLEMENTED`.  Clients can use Operations.GetOperation or other methods to check whether
            the cancellation succeeded or whether the operation completed despite cancellation. On successful
            cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value
            with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.CancelRequest.#ctor(Google.Apis.Services.IClientService,Google.Apis.Vision.v1.Data.CancelOperationRequest,System.String)">
            <summary>Constructs a new Cancel request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.CancelRequest.Name">
            <summary>The name of the operation resource to be cancelled.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.CancelRequest.Body">
            <summary>Gets or sets the body of this request.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.CancelRequest.GetBody">
            <summary>Returns the body of the request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.CancelRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.CancelRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.CancelRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.CancelRequest.InitParameters">
            <summary>Initializes Cancel parameter list.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.Delete(System.String)">
            <summary>Deletes a long-running operation. This method indicates that the client is no longer interested in
            the operation result. It does not cancel the operation. If the server doesn't support this method, it
            returns `google.rpc.Code.UNIMPLEMENTED`.</summary>
            <param name="name">The name of the operation resource to be deleted.</param>
        </member>
        <member name="T:Google.Apis.Vision.v1.OperationsResource.DeleteRequest">
            <summary>Deletes a long-running operation. This method indicates that the client is no longer interested in
            the operation result. It does not cancel the operation. If the server doesn't support this method, it
            returns `google.rpc.Code.UNIMPLEMENTED`.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.DeleteRequest.#ctor(Google.Apis.Services.IClientService,System.String)">
            <summary>Constructs a new Delete request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.DeleteRequest.Name">
            <summary>The name of the operation resource to be deleted.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.DeleteRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.DeleteRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.DeleteRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.DeleteRequest.InitParameters">
            <summary>Initializes Delete parameter list.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.Get(System.String)">
            <summary>Gets the latest state of a long-running operation.  Clients can use this method to poll the
            operation result at intervals as recommended by the API service.</summary>
            <param name="name">The name of the operation resource.</param>
        </member>
        <member name="T:Google.Apis.Vision.v1.OperationsResource.GetRequest">
            <summary>Gets the latest state of a long-running operation.  Clients can use this method to poll the
            operation result at intervals as recommended by the API service.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.GetRequest.#ctor(Google.Apis.Services.IClientService,System.String)">
            <summary>Constructs a new Get request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.GetRequest.Name">
            <summary>The name of the operation resource.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.GetRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.GetRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.GetRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.GetRequest.InitParameters">
            <summary>Initializes Get parameter list.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.List(System.String)">
             <summary>Lists operations that match the specified filter in the request. If the server doesn't support this
             method, it returns `UNIMPLEMENTED`.
            
             NOTE: the `name` binding allows API services to override the binding to use different resource name schemes,
             such as `users/operations`. To override the binding, API services can add a binding such as
             `"/v1/{name=users}/operations"` to their service configuration. For backwards compatibility, the default
             name includes the operations collection id, however overriding users must ensure the name binding is the
             parent resource, without the operations collection id.</summary>
             <param name="name">The name of the operation's parent resource.</param>
        </member>
        <member name="T:Google.Apis.Vision.v1.OperationsResource.ListRequest">
             <summary>Lists operations that match the specified filter in the request. If the server doesn't support this
             method, it returns `UNIMPLEMENTED`.
            
             NOTE: the `name` binding allows API services to override the binding to use different resource name schemes,
             such as `users/operations`. To override the binding, API services can add a binding such as
             `"/v1/{name=users}/operations"` to their service configuration. For backwards compatibility, the default
             name includes the operations collection id, however overriding users must ensure the name binding is the
             parent resource, without the operations collection id.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.ListRequest.#ctor(Google.Apis.Services.IClientService,System.String)">
            <summary>Constructs a new List request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.ListRequest.Name">
            <summary>The name of the operation's parent resource.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.ListRequest.PageToken">
            <summary>The standard list page token.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.ListRequest.PageSize">
            <summary>The standard list page size.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.ListRequest.Filter">
            <summary>The standard list filter.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.ListRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.ListRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.OperationsResource.ListRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.Vision.v1.OperationsResource.ListRequest.InitParameters">
            <summary>Initializes List parameter list.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.AnnotateImageRequest">
            <summary>Request for performing Google Cloud Vision API tasks over a user-provided image, with user-requested
            features.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageRequest.Features">
            <summary>Requested features.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageRequest.Image">
            <summary>The image to be processed.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageRequest.ImageContext">
            <summary>Additional context that may accompany the image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageRequest.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.AnnotateImageResponse">
            <summary>Response to an image annotation request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.CropHintsAnnotation">
            <summary>If present, crop hints have completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.Error">
            <summary>If set, represents the error message for the operation. Note that filled-in image annotations are
            guaranteed to be correct, even when `error` is set.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.FaceAnnotations">
            <summary>If present, face detection has completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.FullTextAnnotation">
            <summary>If present, text (OCR) detection or document (OCR) text detection has completed successfully. This
            annotation provides the structural hierarchy for the OCR detected text.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.ImagePropertiesAnnotation">
            <summary>If present, image properties were extracted successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.LabelAnnotations">
            <summary>If present, label detection has completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.LandmarkAnnotations">
            <summary>If present, landmark detection has completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.LogoAnnotations">
            <summary>If present, logo detection has completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.SafeSearchAnnotation">
            <summary>If present, safe-search annotation has completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.TextAnnotations">
            <summary>If present, text (OCR) detection has completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.WebDetection">
            <summary>If present, web detection has completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.AnnotateImageResponse.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.BatchAnnotateImagesRequest">
            <summary>Multiple image annotation requests are batched into a single service call.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.BatchAnnotateImagesRequest.Requests">
            <summary>Individual image annotation requests for this batch.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.BatchAnnotateImagesRequest.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.BatchAnnotateImagesResponse">
            <summary>Response to a batch image annotation request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.BatchAnnotateImagesResponse.Responses">
            <summary>Individual responses to image annotation requests within the batch.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.BatchAnnotateImagesResponse.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Block">
            <summary>Logical element on the page.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Block.BlockType">
            <summary>Detected block type (text, image etc) for this block.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Block.BoundingBox">
             <summary>The bounding box for the block. The vertices are in the order of top-left, top-right, bottom-right,
             bottom-left. When a rotation of the bounding box is detected the rotation is represented as around the top-
             left corner as defined when the text is read in the 'natural' orientation. For example:
            
             * when the text is horizontal it might look like:
            
             0----1 |    | 3----2
            
             * when it's rotated 180 degrees around the top-left corner it becomes:
            
             2----3 |    | 1----0
            
             and the vertice order will still be (0, 1, 2, 3).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Block.Confidence">
            <summary>Confidence of the OCR results on the block. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Block.Paragraphs">
            <summary>List of paragraphs in this block (if this blocks is of type text).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Block.Property">
            <summary>Additional information detected for the block.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Block.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.BoundingPoly">
            <summary>A bounding polygon for the detected image annotation.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.BoundingPoly.Vertices">
            <summary>The bounding polygon vertices.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.BoundingPoly.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.CancelOperationRequest">
            <summary>The request message for Operations.CancelOperation.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CancelOperationRequest.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "T:Google.Apis.Vision.v1.Data.Color" -->
        <member name="P:Google.Apis.Vision.v1.Data.Color.Alpha">
             <summary>The fraction of this color that should be applied to the pixel. That is, the final pixel color is
             defined by the equation:
            
             pixel color = alpha * (this color) + (1.0 - alpha) * (background color)
            
             This means that a value of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to a
             completely transparent color. This uses a wrapper message rather than a simple float scalar so that it is
             possible to distinguish between a default value and the value being unset. If omitted, this color object is
             to be rendered as a solid color (as if the alpha value had been explicitly given with a value of
             1.0).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Color.Blue">
            <summary>The amount of blue in the color as a value in the interval [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Color.Green">
            <summary>The amount of green in the color as a value in the interval [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Color.Red">
            <summary>The amount of red in the color as a value in the interval [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Color.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.ColorInfo">
            <summary>Color information consists of RGB channels, score, and the fraction of the image that the color
            occupies in the image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ColorInfo.Color">
            <summary>RGB components of the color.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ColorInfo.PixelFraction">
            <summary>The fraction of pixels the color occupies in the image. Value in range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ColorInfo.Score">
            <summary>Image-specific score for this color. Value in range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ColorInfo.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.CropHint">
            <summary>Single crop hint that is used to generate a new crop when serving an image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHint.BoundingPoly">
            <summary>The bounding polygon for the crop region. The coordinates of the bounding box are in the original
            image's scale, as returned in `ImageParams`.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHint.Confidence">
            <summary>Confidence of this being a salient region.  Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHint.ImportanceFraction">
            <summary>Fraction of importance of this salient region with respect to the original image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHint.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.CropHintsAnnotation">
            <summary>Set of crop hints that are used to generate new crops when serving images.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHintsAnnotation.CropHints">
            <summary>Crop hint results.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHintsAnnotation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.CropHintsParams">
            <summary>Parameters for crop hints annotation request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHintsParams.AspectRatios">
            <summary>Aspect ratios in floats, representing the ratio of the width to the height of the image. For
            example, if the desired aspect ratio is 4/3, the corresponding float value should be 1.33333.  If not
            specified, the best possible crop is returned. The number of provided aspect ratios is limited to a maximum
            of 16; any aspect ratios provided after the 16th are ignored.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.CropHintsParams.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.DetectedBreak">
            <summary>Detected start or end of a structural component.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DetectedBreak.IsPrefix">
            <summary>True if break prepends the element.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DetectedBreak.Type">
            <summary>Detected break type.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DetectedBreak.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.DetectedLanguage">
            <summary>Detected language for a structural component.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DetectedLanguage.Confidence">
            <summary>Confidence of detected language. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DetectedLanguage.LanguageCode">
            <summary>The BCP-47 language code, such as "en-US" or "sr-Latn". For more information, see
            http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DetectedLanguage.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.DominantColorsAnnotation">
            <summary>Set of dominant colors and their corresponding scores.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DominantColorsAnnotation.Colors">
            <summary>RGB color values with their score and pixel fraction.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.DominantColorsAnnotation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Empty">
             <summary>A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A
             typical example is to use it as the request or the response type of an API method. For instance:
            
             service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
            
             The JSON representation for `Empty` is empty JSON object `{}`.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Empty.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.EntityAnnotation">
            <summary>Set of detected entity features.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.BoundingPoly">
            <summary>Image region to which this entity belongs. Not produced for `LABEL_DETECTION` features.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Confidence">
            <summary>**Deprecated. Use `score` instead.** The accuracy of the entity detection in an image. For example,
            for an image in which the "Eiffel Tower" entity is detected, this field represents the confidence that there
            is a tower in the query image. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Description">
            <summary>Entity textual description, expressed in its `locale` language.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Locale">
            <summary>The language code for the locale in which the entity textual `description` is expressed.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Locations">
            <summary>The location information for the detected entity. Multiple `LocationInfo` elements can be present
            because one location may indicate the location of the scene in the image, and another location may indicate
            the location of the place where the image was taken. Location information is usually present for
            landmarks.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Mid">
            <summary>Opaque entity ID. Some IDs may be available in [Google Knowledge Graph Search
            API](https://developers.google.com/knowledge-graph/).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Properties">
            <summary>Some entities may have optional user-supplied `Property` (name/value) fields, such a score or
            string that qualifies the entity.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Score">
            <summary>Overall score of the result. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.Topicality">
            <summary>The relevancy of the ICA (Image Content Annotation) label to the image. For example, the relevancy
            of "tower" is likely higher to an image containing the detected "Eiffel Tower" than to an image containing a
            detected distant towering building, even though the confidence that there is a tower in each image may be
            the same. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.EntityAnnotation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.FaceAnnotation">
            <summary>A face annotation object contains the results of face detection.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.AngerLikelihood">
            <summary>Anger likelihood.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.BlurredLikelihood">
            <summary>Blurred likelihood.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.BoundingPoly">
            <summary>The bounding polygon around the face. The coordinates of the bounding box are in the original
            image's scale, as returned in `ImageParams`. The bounding box is computed to "frame" the face in accordance
            with human expectations. It is based on the landmarker results. Note that one or more x and/or y coordinates
            may not be generated in the `BoundingPoly` (the polygon will be unbounded) if only a partial face appears in
            the image to be annotated.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.DetectionConfidence">
            <summary>Detection confidence. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.FdBoundingPoly">
            <summary>The `fd_bounding_poly` bounding polygon is tighter than the `boundingPoly`, and encloses only the
            skin part of the face. Typically, it is used to eliminate the face from any image analysis that detects the
            "amount of skin" visible in an image. It is not based on the landmarker results, only on the initial face
            detection, hence the fd (face detection) prefix.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.HeadwearLikelihood">
            <summary>Headwear likelihood.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.JoyLikelihood">
            <summary>Joy likelihood.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.LandmarkingConfidence">
            <summary>Face landmarking confidence. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.Landmarks">
            <summary>Detected face landmarks.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.PanAngle">
            <summary>Yaw angle, which indicates the leftward/rightward angle that the face is pointing relative to the
            vertical plane perpendicular to the image. Range [-180,180].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.RollAngle">
            <summary>Roll angle, which indicates the amount of clockwise/anti-clockwise rotation of the face relative to
            the image vertical about the axis perpendicular to the face. Range [-180,180].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.SorrowLikelihood">
            <summary>Sorrow likelihood.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.SurpriseLikelihood">
            <summary>Surprise likelihood.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.TiltAngle">
            <summary>Pitch angle, which indicates the upwards/downwards angle that the face is pointing relative to the
            image's horizontal plane. Range [-180,180].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.UnderExposedLikelihood">
            <summary>Under-exposed likelihood.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.FaceAnnotation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Feature">
            <summary>The type of Google Cloud Vision API detection to perform, and the maximum number of results to return
            for that type. Multiple `Feature` objects can be specified in the `features` list.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Feature.MaxResults">
            <summary>Maximum number of results of this type. Does not apply to `TEXT_DETECTION`,
            `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Feature.Model">
            <summary>Model to use for the feature. Supported values: "builtin/stable" (the default if unset) and
            "builtin/latest".</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Feature.Type">
            <summary>The feature type.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Feature.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1AsyncAnnotateFileResponse">
            <summary>The response for a single offline file annotation request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1AsyncAnnotateFileResponse.OutputConfig">
            <summary>The output location and metadata from AsyncAnnotateFileRequest.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1AsyncAnnotateFileResponse.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1AsyncBatchAnnotateFilesResponse">
            <summary>Response to an async batch file annotation request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1AsyncBatchAnnotateFilesResponse.Responses">
            <summary>The list of file annotation responses, one for each request in
            AsyncBatchAnnotateFilesRequest.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1AsyncBatchAnnotateFilesResponse.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1GcsDestination">
            <summary>The Google Cloud Storage location where the output will be written to.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1GcsDestination.Uri">
             <summary>Google Cloud Storage URI where the results will be stored. Results will be in JSON format and
             preceded by its corresponding input URI. This field can either represent a single file, or a prefix for
             multiple outputs. Prefixes must end in a `/`.
            
             Examples:
            
             *    File: gs://bucket-name/filename.json *    Prefix: gs://bucket-name/prefix/here/ *    File: gs://bucket-
             name/prefix/here
            
             If multiple outputs, each response is still AnnotateFileResponse, each of which contains some subset of the
             full list of AnnotateImageResponse. Multiple outputs can happen if, for example, the output JSON is too
             large and overflows into multiple sharded files.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1GcsDestination.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OperationMetadata">
            <summary>Contains metadata for the BatchAnnotateImages operation.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OperationMetadata.CreateTime">
            <summary>The time when the batch request was received.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OperationMetadata.State">
            <summary>Current state of the batch operation.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OperationMetadata.UpdateTime">
            <summary>The time when the operation result was last updated.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OperationMetadata.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OutputConfig">
            <summary>The desired output location and metadata.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OutputConfig.BatchSize">
             <summary>The max number of response protos to put into each output JSON file on GCS. The valid range is [1,
             100]. If not specified, the default value is 20.
            
             For example, for one pdf file with 100 pages, 100 response protos will be generated. If `batch_size` = 20,
             then 5 json files each containing 20 response protos will be written under the prefix
             `gcs_destination`.`uri`.
            
             Currently, batch_size only applies to GcsDestination, with potential future support for other output
             configurations.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OutputConfig.GcsDestination">
            <summary>The Google Cloud Storage location to write the output(s) to.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.GoogleCloudVisionV1p2beta1OutputConfig.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Image">
            <summary>Client image to perform Google Cloud Vision API tasks over.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Image.Content">
            <summary>Image content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use
            a pure binary representation, whereas JSON representations use base64.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Image.Source">
            <summary>Google Cloud Storage image location, or publicly-accessible image URL. If both `content` and
            `source` are provided for an image, `content` takes precedence and is used to perform the image annotation
            request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Image.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.ImageContext">
            <summary>Image context and/or feature-specific parameters.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageContext.CropHintsParams">
            <summary>Parameters for crop hints annotation request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageContext.LanguageHints">
            <summary>List of languages to use for TEXT_DETECTION. In most cases, an empty value yields the best results
            since it enables automatic language detection. For languages based on the Latin alphabet, setting
            `language_hints` is not needed. In rare cases, when the language of the text in the image is known, setting
            a hint will help get better results (although it will be a significant hindrance if the hint is wrong). Text
            detection returns an error if one or more of the specified languages is not one of the [supported
            languages](/vision/docs/languages).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageContext.LatLongRect">
            <summary>lat/long rectangle that specifies the location of the image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageContext.WebDetectionParams">
            <summary>Parameters for web detection.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageContext.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.ImageProperties">
            <summary>Stores image properties, such as dominant colors.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageProperties.DominantColors">
            <summary>If present, dominant colors completed successfully.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageProperties.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.ImageSource">
            <summary>External image source (Google Cloud Storage or web URL image location).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageSource.GcsImageUri">
             <summary>**Use `image_uri` instead.**
            
             The Google Cloud Storage  URI of the form `gs://bucket_name/object_name`. Object versioning is not
             supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for
             more info.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageSource.ImageUri">
             <summary>The URI of the source image. Can be either:
            
             1. A Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not
             supported. See [Google Cloud Storage Request URIs](https://cloud.google.com/storage/docs/reference-uris) for
             more info.
            
             2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from HTTP/HTTPS URLs, Google cannot
             guarantee that the request will be completed. Your request may fail if the specified host denies the request
             (e.g. due to request throttling or DOS prevention), or if Google throttles requests to the site for abuse
             prevention. You should not depend on externally-hosted images for production applications.
            
             When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes precedence.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ImageSource.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Landmark">
            <summary>A face-specific landmark (for example, a face feature).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Landmark.Position">
            <summary>Face landmark position.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Landmark.Type">
            <summary>Face landmark type.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Landmark.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.LatLng">
            <summary>An object representing a latitude/longitude pair. This is expressed as a pair of doubles representing
            degrees latitude and degrees longitude. Unless specified otherwise, this must conform to the WGS84 standard.
            Values must be within normalized ranges.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LatLng.Latitude">
            <summary>The latitude in degrees. It must be in the range [-90.0, +90.0].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LatLng.Longitude">
            <summary>The longitude in degrees. It must be in the range [-180.0, +180.0].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LatLng.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.LatLongRect">
            <summary>Rectangle determined by min and max `LatLng` pairs.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LatLongRect.MaxLatLng">
            <summary>Max lat/long pair.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LatLongRect.MinLatLng">
            <summary>Min lat/long pair.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LatLongRect.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.ListOperationsResponse">
            <summary>The response message for Operations.ListOperations.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ListOperationsResponse.NextPageToken">
            <summary>The standard List next-page token.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ListOperationsResponse.Operations">
            <summary>A list of operations that matches the specified filter in the request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.ListOperationsResponse.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.LocationInfo">
            <summary>Detected entity location information.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LocationInfo.LatLng">
            <summary>lat/long location coordinates.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.LocationInfo.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Operation">
            <summary>This resource represents a long-running operation that is the result of a network API call.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Operation.Done">
            <summary>If the value is `false`, it means the operation is still in progress. If `true`, the operation is
            completed, and either `error` or `response` is available.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Operation.Error">
            <summary>The error result of the operation in case of failure or cancellation.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Operation.Metadata">
            <summary>Service-specific metadata associated with the operation.  It typically contains progress
            information and common metadata such as create time. Some services might not provide such metadata.  Any
            method that returns a long-running operation should document the metadata type, if any.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Operation.Name">
            <summary>The server-assigned name, which is only unique within the same service that originally returns it.
            If you use the default HTTP mapping, the `name` should have the format of
            `operations/some/unique/name`.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Operation.Response">
            <summary>The normal response of the operation in case of success.  If the original method returns no data on
            success, such as `Delete`, the response is `google.protobuf.Empty`.  If the original method is standard
            `Get`/`Create`/`Update`, the response should be the resource.  For other methods, the response should have
            the type `XxxResponse`, where `Xxx` is the original method name.  For example, if the original method name
            is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Operation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Page">
            <summary>Detected page from OCR.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Page.Blocks">
            <summary>List of blocks of text, images etc on this page.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Page.Confidence">
            <summary>Confidence of the OCR results on the page. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Page.Height">
            <summary>Page height. For PDFs the unit is points. For images (including TIFFs) the unit is
            pixels.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Page.Property">
            <summary>Additional information detected on the page.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Page.Width">
            <summary>Page width. For PDFs the unit is points. For images (including TIFFs) the unit is pixels.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Page.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Paragraph">
            <summary>Structural unit of text representing a number of words in certain order.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Paragraph.BoundingBox">
            <summary>The bounding box for the paragraph. The vertices are in the order of top-left, top-right, bottom-
            right, bottom-left. When a rotation of the bounding box is detected the rotation is represented as around
            the top-left corner as defined when the text is read in the 'natural' orientation. For example: * when the
            text is horizontal it might look like: 0----1 |    | 3----2 * when it's rotated 180 degrees around the top-
            left corner it becomes: 2----3 |    | 1----0 and the vertice order will still be (0, 1, 2, 3).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Paragraph.Confidence">
            <summary>Confidence of the OCR results for the paragraph. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Paragraph.Property">
            <summary>Additional information detected for the paragraph.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Paragraph.Words">
            <summary>List of words in this paragraph.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Paragraph.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Position">
            <summary>A 3D position in the image, used primarily for Face detection landmarks. A valid Position must have
            both x and y coordinates. The position coordinates are in the same scale as the original image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Position.X">
            <summary>X coordinate.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Position.Y">
            <summary>Y coordinate.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Position.Z">
            <summary>Z coordinate (or depth).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Position.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Property">
            <summary>A `Property` consists of a user-supplied name/value pair.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Property.Name">
            <summary>Name of the property.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Property.Uint64Value">
            <summary>Value of numeric properties.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Property.Value">
            <summary>Value of the property.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Property.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.SafeSearchAnnotation">
            <summary>Set of features pertaining to the image, computed by computer vision methods over safe-search verticals
            (for example, adult, spoof, medical, violence).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.SafeSearchAnnotation.Adult">
            <summary>Represents the adult content likelihood for the image. Adult content may contain elements such as
            nudity, pornographic images or cartoons, or sexual activities.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.SafeSearchAnnotation.Medical">
            <summary>Likelihood that this is a medical image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.SafeSearchAnnotation.Racy">
            <summary>Likelihood that the request image contains racy content. Racy content may include (but is not
            limited to) skimpy or sheer clothing, strategically covered nudity, lewd or provocative poses, or close-ups
            of sensitive body areas.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.SafeSearchAnnotation.Spoof">
            <summary>Spoof likelihood. The likelihood that an modification was made to the image's canonical version to
            make it appear funny or offensive.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.SafeSearchAnnotation.Violence">
            <summary>Likelihood that this image contains violent content.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.SafeSearchAnnotation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Status">
             <summary>The `Status` type defines a logical error model that is suitable for different programming
             environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). The error model
             is designed to be:
            
             - Simple to use and understand for most users - Flexible enough to meet unexpected needs
            
             # Overview
            
             The `Status` message contains three pieces of data: error code, error message, and error details. The error code
             should be an enum value of google.rpc.Code, but it may accept additional error codes if needed.  The error
             message should be a developer-facing English message that helps developers *understand* and *resolve* the error.
             If a localized user-facing error message is needed, put the localized message in the error details or localize
             it in the client. The optional error details may contain arbitrary information about the error. There is a
             predefined set of error detail types in the package `google.rpc` that can be used for common error conditions.
            
             # Language mapping
            
             The `Status` message is the logical representation of the error model, but it is not necessarily the actual wire
             format. When the `Status` message is exposed in different client libraries and different wire protocols, it can
             be mapped differently. For example, it will likely be mapped to some exceptions in Java, but more likely mapped
             to some error codes in C.
            
             # Other uses
            
             The error model and the `Status` message can be used in a variety of environments, either with or without APIs,
             to provide a consistent developer experience across different environments.
            
             Example uses of this error model include:
            
             - Partial errors. If a service needs to return partial errors to the client, it may embed the `Status` in the
             normal response to indicate the partial errors.
            
             - Workflow errors. A typical workflow has multiple steps. Each step may have a `Status` message for error
             reporting.
            
             - Batch operations. If a client uses batch request and batch response, the `Status` message should be used
             directly inside batch response, one for each error sub-response.
            
             - Asynchronous operations. If an API call embeds asynchronous operation results in its response, the status of
             those operations should be represented directly using the `Status` message.
            
             - Logging. If some API errors are stored in logs, the message `Status` could be used directly after any
             stripping needed for security/privacy reasons.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Status.Code">
            <summary>The status code, which should be an enum value of google.rpc.Code.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Status.Details">
            <summary>A list of messages that carry the error details.  There is a common set of message types for APIs
            to use.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Status.Message">
            <summary>A developer-facing error message, which should be in English. Any user-facing error message should
            be localized and sent in the google.rpc.Status.details field, or localized by the client.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Status.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Symbol">
            <summary>A single symbol representation.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Symbol.BoundingBox">
            <summary>The bounding box for the symbol. The vertices are in the order of top-left, top-right, bottom-
            right, bottom-left. When a rotation of the bounding box is detected the rotation is represented as around
            the top-left corner as defined when the text is read in the 'natural' orientation. For example: * when the
            text is horizontal it might look like: 0----1 |    | 3----2 * when it's rotated 180 degrees around the top-
            left corner it becomes: 2----3 |    | 1----0 and the vertice order will still be (0, 1, 2, 3).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Symbol.Confidence">
            <summary>Confidence of the OCR results for the symbol. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Symbol.Property">
            <summary>Additional information detected for the symbol.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Symbol.Text">
            <summary>The actual UTF-8 representation of the symbol.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Symbol.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.TextAnnotation">
            <summary>TextAnnotation contains a structured representation of OCR extracted text. The hierarchy of an OCR
            extracted text structure is like this: TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol Each
            structural component, starting from Page, may further have their own properties. Properties describe detected
            languages, breaks etc.. Please refer to the TextAnnotation.TextProperty message definition below for more
            detail.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.TextAnnotation.Pages">
            <summary>List of pages detected by OCR.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.TextAnnotation.Text">
            <summary>UTF-8 text detected on the pages.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.TextAnnotation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.TextProperty">
            <summary>Additional information detected on the structural component.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.TextProperty.DetectedBreak">
            <summary>Detected start or end of a text segment.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.TextProperty.DetectedLanguages">
            <summary>A list of detected languages together with confidence.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.TextProperty.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Vertex">
            <summary>A vertex represents a 2D point in the image. NOTE: the vertex coordinates are in the same scale as the
            original image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Vertex.X">
            <summary>X coordinate.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Vertex.Y">
            <summary>Y coordinate.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Vertex.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.WebDetection">
            <summary>Relevant information for the image from the Internet.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetection.BestGuessLabels">
            <summary>Best guess text labels for the request image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetection.FullMatchingImages">
            <summary>Fully matching images from the Internet. Can include resized copies of the query image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetection.PagesWithMatchingImages">
            <summary>Web pages containing the matching images from the Internet.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetection.PartialMatchingImages">
            <summary>Partial matching images from the Internet. Those images are similar enough to share some key-point
            features. For example an original image will likely have partial matching for its crops.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetection.VisuallySimilarImages">
            <summary>The visually similar image results.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetection.WebEntities">
            <summary>Deduced entities from similar images on the Internet.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetection.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.WebDetectionParams">
            <summary>Parameters for web detection request.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetectionParams.IncludeGeoResults">
            <summary>Whether to include results derived from the geo information in the image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebDetectionParams.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.WebEntity">
            <summary>Entity deduced from similar images on the Internet.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebEntity.Description">
            <summary>Canonical description of the entity, in English.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebEntity.EntityId">
            <summary>Opaque entity ID.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebEntity.Score">
            <summary>Overall relevancy score for the entity. Not normalized and not comparable across different image
            queries.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebEntity.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.WebImage">
            <summary>Metadata for online images.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebImage.Score">
            <summary>(Deprecated) Overall relevancy score for the image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebImage.Url">
            <summary>The result image URL.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebImage.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.WebLabel">
            <summary>Label to provide extra metadata for the web detection.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebLabel.Label">
            <summary>Label for extra metadata.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebLabel.LanguageCode">
            <summary>The BCP-47 language code for `label`, such as "en-US" or "sr-Latn". For more information, see
            http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebLabel.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.WebPage">
            <summary>Metadata for web pages.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebPage.FullMatchingImages">
            <summary>Fully matching images on the page. Can include resized copies of the query image.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebPage.PageTitle">
            <summary>Title for the web page, may contain HTML markups.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebPage.PartialMatchingImages">
            <summary>Partial matching images on the page. Those images are similar enough to share some key-point
            features. For example an original image will likely have partial matching for its crops.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebPage.Score">
            <summary>(Deprecated) Overall relevancy score for the web page.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebPage.Url">
            <summary>The result web page URL.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.WebPage.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.Vision.v1.Data.Word">
            <summary>A word representation.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Word.BoundingBox">
            <summary>The bounding box for the word. The vertices are in the order of top-left, top-right, bottom-right,
            bottom-left. When a rotation of the bounding box is detected the rotation is represented as around the top-
            left corner as defined when the text is read in the 'natural' orientation. For example: * when the text is
            horizontal it might look like: 0----1 |    | 3----2 * when it's rotated 180 degrees around the top-left
            corner it becomes: 2----3 |    | 1----0 and the vertice order will still be (0, 1, 2, 3).</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Word.Confidence">
            <summary>Confidence of the OCR results for the word. Range [0, 1].</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Word.Property">
            <summary>Additional information detected for the word.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Word.Symbols">
            <summary>List of symbols in the word. The order of the symbols follows the natural reading order.</summary>
        </member>
        <member name="P:Google.Apis.Vision.v1.Data.Word.ETag">
            <summary>The ETag of the item.</summary>
        </member>
    </members>
</doc>
